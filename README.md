![Header Logo](images/header.png)
# Data Engines Benchmark

Como voluntÃ¡rio engenheiro de dados Jr na [SouJunior](https://soujunior.tech), fui encarregado de uma tarefa crucial: comparar diferentes engines de processamento de dados para identificar a melhor opÃ§Ã£o para nossa pipeline de ETL (ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carga).

Nossa pipeline processa dados extraÃ­dos da pÃ¡gina do LinkedIn da SouJunior, com extraÃ§Ãµes ocorrendo a cada 15 dias. Em cada rotina de extraÃ§Ã£o, sÃ£o gerados quatro arquivos no formato .xls / .xlsx, correspondentes Ã s categorias de `ConteÃºdo`, `Visitantes`, `Seguidores` e `Concorrentes`.

Esse readme contÃ©m detalhes tÃ©cnicos, informaÃ§Ãµes do cÃ³digo e como executar. Para conferir o artigo que explora os resultados de cada engine de processamento, acesse o [artigo](article.md).

## ğŸ“ SumÃ¡rio

- [Data Engines Benchmark](#data-engines-benchmark)
  - [ğŸ“ SumÃ¡rio](#-sumÃ¡rio)
  - [âš™ï¸ Engines Utilizadas](#ï¸-engines-utilizadas)
  - [ğŸ“¦ InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
  - [ğŸ“ Estrutura do cÃ³digo](#-estrutura-do-cÃ³digo)
  - [ğŸ“ Detalhes tÃ©cnicos](#-detalhes-tÃ©cnicos)
    - [GeraÃ§Ã£o de MÃ©tricas](#geraÃ§Ã£o-de-mÃ©tricas)
      - [Funcionamento](#funcionamento)
      - [Exemplo de uso](#exemplo-de-uso)
      - [Salvando MÃ©tricas](#salvando-mÃ©tricas)
    - [Peculiaridades de cada engine](#peculiaridades-de-cada-engine)
      - [Pandas](#pandas)
      - [Polars](#polars)
      - [DuckDB](#duckdb)
  - [â–¶ï¸ Como executar](#ï¸-como-executar)
  - [ğŸ™ Agradecimentos](#-agradecimentos)
  - [ğŸ’¡ ContribuiÃ§Ãµes](#-contribuiÃ§Ãµes)
  - [ğŸŒŸ Esmola Pill](#-esmola-pill)

## âš™ï¸ Engines Utilizadas

- [**DuckDB**](https://duckdb.org/docs/api/python/overview.html)
- [**Pandas**](https://pandas.pydata.org/docs/getting_started/index.html#getting-started)
- [**Polars**](https://docs.pola.rs/user-guide/installation/)

## ğŸ“¦ InstalaÃ§Ã£o

1. Clone o repositÃ³rio no seu computador.
```bash
git clone https://github.com/moscarde/data-engines-benchmark.git
cd data-engines-benchmark
```


2. Para instalar as bibliotecas, execute o seguinte cÃ³digo:

```bash
pip install pandas
pip install openpyxl
pip install polars # ou polars-lts-cpu para processadores mais antigos
pip install duckdb

```

ğŸ’¡ **Notas**: 

1. Dependendo do seu processador, pode ser necessÃ¡rio instalar a biblioteca `polars-lts-cpu`. 

2. Os resultados desse estudo foram gerados a partir das seguintes versÃµes das bibliotecas: `pandas==2.2.2`, `polars-lts-cpu==0.20.30` e `duckdb==1.0.0`.

## ğŸ“ Estrutura do cÃ³digo

```
â”œâ”€â”€ data/linkedin/
        â”œâ”€â”€ clean/ # Local onde serÃ¡ salvo os dados limpos e resultados dos testes
        â”œâ”€â”€ raw_1y/ # 1 ano de dados brutos
            â”œâ”€â”€ Concorrentes/
                â”œâ”€â”€ *Anos/
                    â”œâ”€â”€ *Meses/
            â”œâ”€â”€ ConteÃºdo/
                â”œâ”€â”€ *Anos/
                    â”œâ”€â”€ *Meses/
            â”œâ”€â”€ Seguidores/
                â”œâ”€â”€ *Anos/
                    â”œâ”€â”€ *Meses/
            â”œâ”€â”€ Visitantes/
                â”œâ”€â”€ *Anos/
                    â”œâ”€â”€ *Meses/
        â”œâ”€â”€ raw_2y/ # 2 anos de dados brutos 
        â”œâ”€â”€ raw_6y/ # 6 anos de dados brutos
        â”œâ”€â”€ raw_unique_extraction/ # Arquivos de extraÃ§Ã£o Ãºnica (Utilizado na segunda abordagem)
â”œâ”€â”€ engines/
    â”œâ”€â”€ method_1/ # Classes de engines programadas para executar o mÃ©todo 1
    â”œâ”€â”€ method_2/ # Classes de engines programadas para executar o mÃ©todo 2
â”œâ”€â”€ plots/ # GrÃ¡ficos gerados no script de anÃ¡lise de resultados
â”œâ”€â”€ engines_test_m1.py # Script de teste para o mÃ©todo 1
â”œâ”€â”€ engines_test_m2.py # Script de teste para o mÃ©todo 2
â”œâ”€â”€ performance_analysis.py # Notebook para exploraÃ§Ã£o dos resultados

```

## ğŸ“ Detalhes tÃ©cnicos

### GeraÃ§Ã£o de MÃ©tricas

Para medir o tempo de execuÃ§Ã£o das funÃ§Ãµes crÃ­ticas no processo de ETL, foi criado um decorador `@timer`.

```python	
def timer(func):
    """
    FunÃ§Ã£o para medir o tempo de execuÃ§Ã£o de uma funÃ§Ã£o.

    ParÃ¢metros:
    func (function): FunÃ§Ã£o a ser medida.

    Retorno:
    function: FunÃ§Ã£o com o tempo de execuÃ§Ã£o medido.
    """
    def wrapper(*args, **kwargs):
        """
        FunÃ§Ã£o que mede o tempo de execuÃ§Ã£o de uma funÃ§Ã£o.

        ParÃ¢metros:
        *args: Lista de parÃ¢metros passados para a funÃ§Ã£o.
        **kwargs: DicionÃ¡rio de parÃ¢metros passados para a funÃ§Ã£o.

        Retorno:
        function: FunÃ§Ã£o com o tempo de execuÃ§Ã£o medido.
        """
        start_time = time.time()
        result = func(*args, **kwargs)
        elapsed_time = time.time() - start_time
        print(f"[{args[0].engine}] {func.__name__}: {elapsed_time:.2f} seconds")
        args[0].engine_metrics[func.__name__] = elapsed_time.__round__(2)
        return result

    return wrapper
```

#### Funcionamento

1. **DefiniÃ§Ã£o do Decorador:** A funÃ§Ã£o `timer` Ã© um decorador que mede o tempo de execuÃ§Ã£o de outra funÃ§Ã£o. Ela utiliza o mÃ³dulo `time` para capturar o tempo inicial antes da execuÃ§Ã£o e o tempo final apÃ³s a execuÃ§Ã£o da funÃ§Ã£o decorada.

2. **Wrapper:** Dentro do decorador, a funÃ§Ã£o `wrapper` Ã© definida para envolver a funÃ§Ã£o original. Ela captura o tempo de inÃ­cio, executa a funÃ§Ã£o original, calcula o tempo decorrido e imprime o tempo de execuÃ§Ã£o.

3. **Armazenamento das MÃ©tricas:** O tempo de execuÃ§Ã£o Ã© armazenado no atributo `engine_metrics` da instÃ¢ncia da classe. Isso permite que as mÃ©tricas de desempenho sejam salvas e analisadas posteriormente.

#### Exemplo de uso

O decorador `@timer` Ã© usado na funÃ§Ã£o `extract_data` dentro da classe responsÃ¡vel pelo processamento ETL:

```python
    def steps_etl(self):
        """
        FunÃ§Ã£o para iniciar fluxo de processamento da engine.
        """
        data = self.extract_data()
        data = self.transform_data(data)
        self.load_to_clean(data)
        monthly_data = self.concatenate_monthly_data(data)
        self.export_monthly_data(monthly_data)
        category_data = self.concatenate_category_data(monthly_data)
        self.export_category_data(category_data)

    @timer
    def extract_data(self):
        """
        FunÃ§Ã£o para iniciar o processo de extraÃ§Ã£o de dados da engine.
        """
        data = self.etl.extract_data()
        if self.engine == "duckdb":
            return self.etl.convert_dataframes_to_duckdb(data)
        else:
            return data
```

#### Salvando MÃ©tricas

ApÃ³s a execuÃ§Ã£o das funÃ§Ãµes decoradas, as mÃ©tricas de tempo podem ser salvas em um arquivo CSV para anÃ¡lise posterior:

```python
def save_metrics_to_csv(self, metrics_file="data/linkedin/clean/m1/engines.csv"):
    file_exists = os.path.isfile(metrics_file)
    if file_exists:
        pd.DataFrame(self.engine_metrics, index=[0]).to_csv(
            metrics_file, mode="a", index=False, header=False
        )
    else:
        pd.DataFrame(self.engine_metrics, index=[0]).to_csv(
            metrics_file, index=False
        )
```

### Peculiaridades de cada engine

#### Pandas

Eu jÃ¡ tinha um pouco de experiÃªncia com a biblioteca Pandas, mas trabalhar com uma grande quantidade de dados me proporcionou uma afinidade maior com a ferramenta.

O pandas nÃ£o teve dificuldade com a leitura dos arquivos `.xls` e `.xlsx`. Embora nÃ£o estejam padronizados, com alguns ajustes no cÃ³digo a base de dados Ã© carregada facilmente.

```python
    df = pd.read_excel(
        file["file_path"],
        sheet_name=sheet["sheet_pos"],
        skiprows=sheet["skiprows"],
    )

```

ApÃ³s o tratamento dos dados, o Pandas Ã© usado para concatenar os arquivos em um dataframe, que Ã© entÃ£o exportado para um arquivo CSV.

```python
    dataframe["concatenated_df"].to_csv(
        full_path, index=False, quoting=csv.QUOTE_ALL
    )
```

#### Polars

A biblioteca Polars foi a mais performÃ¡tica, porÃ©m a que mais me trouxe dificuldades. AlÃ©m da documentaÃ§Ã£o oficial nÃ£o explorar profundamente cada funcionalidade (principalmente sobre a leitura de arquivos), outras fontes de referÃªncia que encontrei acabavam trocando termos com os do Pandas por conta da sua similaridade.

```python
    df = pl.read_excel(
        source=file["file_path"],
        sheet_id=sheet["sheet_pos"],
        read_options={"skip_rows": sheet["skiprows"]},
    )
```

```python
    dataframe["concatenated_df"].write_csv(full_path, quote_style="always")
```

#### DuckDB

Esse resultado se deve Ã  leitura dos arquivos .xls e .xlsx, que precisam ser carregados primeiramente para um dataframe Pandas e, em seguida, convertidos para tabelas DuckDB. A curva de aprendizado com a biblioteca DuckDB foi Ã³tima, por conta de utilizar a lÃ³gica de tabelas e queries SQL.

```python
    df = pd.read_excel(
                file["file_path"],
                sheet_name=sheet["sheet_pos"],
                skiprows=sheet["skiprows"],
    )

    # ...

    db_table_name = (
            f"{dataframe['dataframe_name']}_{dataframe['extraction_period']}"
        )
        table_attribute = table_attributes.get(dataframe["dataframe_name"])

        translated_columns = table_attribute.keys()
        dataframe["df"].columns = list(translated_columns)

        self.con.register("temp_table", dataframe["df"])

        columns_definition = ", ".join(
            [f'"{col}" {dtype}' for col, dtype in table_attribute.items()]
        )
        create_table_query = f"CREATE TABLE {db_table_name} ({columns_definition});"
        self.con.execute(create_table_query)

        insert_query = f"INSERT INTO {db_table_name} SELECT "
        for col, dtype in table_attribute.items():
            if dtype == "DATE":
                insert_query += f'CASE WHEN "{col}" IS NULL OR "{col}" = \'\' THEN NULL ELSE STRPTIME(CAST("{col}" AS VARCHAR), \'%m/%d/%Y\') END AS "{col}", '
            else:
                insert_query += f'"{col}", '

        insert_query = insert_query.rstrip(", ") + " FROM temp_table;"

        self.con.execute(insert_query)

        table_dict = {
            "dataframe_name": dataframe["dataframe_name"],
            "extraction_period": dataframe["extraction_period"],
            "db_table_name": db_table_name,
            "export_dir": os.path.join(self.clean_directory, *dataframe["dir"]),
        }

```
_Por conta da quantidade de tabelas sendo processadas simultaneamente para seguir a mesma lÃ³gica das outras engines, precisei utilizar uma lÃ³gica um pouco mais complexa para gerar as queries. O trecho acima resulta em queries assim:_

```SQL

INSERT INTO visitors_location_2024_Mar_2 SELECT "Location", "Total Views" FROM temp_table;

```

ğŸ’¡ **Nota**: Devido Ã  lÃ³gica de processamento diferente das demais, o DuckDB poderia performar melhor caso fosse recompilado e otimizado seguindo seus prÃ³prios princÃ­pios de processamento. A implementaÃ§Ã£o atual foi adaptada para manter a consistÃªncia com as outras engines, o que pode nÃ£o aproveitar todo o potencial de performance do DuckDB.


## â–¶ï¸ Como executar

Adicione arquivos de extraÃ§Ãµes no diretÃ³rio `data/linkedin/raw_1y/*` e `data/linkedin/unique_extraction/` e replique para os demais ambientes fictÃ­cios (2 e 6 anos).

Execute o script de teste `engines_test_m1.py` ou `engines_test_m2.py` de acordo com o mÃ©todo escolhido.

Resultados das engines e mÃ©todos sÃ£o armazenados em `data/linkedin/clean/`.

Estes scripts iteram por todas as 3 engines e para cada engine, testam os 3 ambientes fictÃ­cios.

Para executar individualmente cada engine, execute os respectivos scripts localizados em `engines/method_1` e `engines/method_2`.

ğŸ’¡ **Nota**: O fluxo de processamento de dados trabalhado nÃ£o Ã© o mais performÃ¡tico, por ser o que estamos utilizando na etapa de validaÃ§Ã£o e testes de desenvolvimento. PorÃ©m o mesmo fluxo foi replicado para ambas as engines


## ğŸ™ Agradecimentos

Agradecimentos para o time de dados da [SouJunior](https://soujunior.tech) que colaboraram com o projeto: [Pedro FogaÃ§a](https://github.com/hdind), [Bruna Krobel](https://github.com/Bruna-Krobel) e [Karine Cristina](https://github.com/karinnecristina).

## ğŸ’¡ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues ou enviar pull requests com melhorias e correÃ§Ãµes.

## ğŸŒŸ Esmola Pill

Apoie este projeto deixando uma **Estrelinha**â­ aqui no repositÃ³rio.
